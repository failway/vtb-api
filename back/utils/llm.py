import os
import httpx
from openai import AsyncOpenAI

http_client = httpx.AsyncClient(timeout=30.0, verify=False)

API_LLM = os.getenv("AI_KEY","")

client = AsyncOpenAI(
    api_key=API_LLM,
    base_url="https://api.intelligence.io.solutions/api/v1/",
    http_client=http_client,
)

async def ask_ai(user_message: str, context: str = "") -> str:
    """
    –û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ AI-–º–æ–¥–µ–ª—å –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç.
    context ‚Äî –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Ä–∞—Å—Ö–æ–¥–æ–≤).
    """
    try:
        prompt = (
            f"–¢—ã ‚Äî —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç: {user_message}\n\n"
            f"–í–æ—Ç –∫—Ä–∞—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–æ –µ–≥–æ —Ä–∞—Å—Ö–æ–¥–∞–º:\n{context}, –¥–æ–±–∞–≤—å —Å–º–∞–π–ª–∏–∫–∏ —Ç—É–¥–∞, –≥–¥–µ —É–º–µ—Å—Ç–Ω–æ."
        )

        response = await client.chat.completions.create(
            model="meta-llama/Llama-3.3-70B-Instruct",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.8,
        )

        return response.choices[0].message.content.strip()
    except Exception as e:
        return "–ò–∑–≤–∏–Ω–∏, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç AI. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ üôè"
